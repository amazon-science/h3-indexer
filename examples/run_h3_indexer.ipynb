{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e2a20c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, '/home/madiejf/github-os/h3-indexer/src')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf555b45",
   "metadata": {},
   "source": [
    "### Import package and Set environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d74b62a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h3_indexer\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26a1fab",
   "metadata": {},
   "source": [
    "### Create a Job Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd25fa75",
   "metadata": {},
   "source": [
    "Read a Job Config from a JSON input.\n",
    "\n",
    "This job config is providing a single input, a parquet file in S3. The parquet file is a line-type geometry dataset with a unique ID column called \"route_id\" and a geometry column called \"geom_geojson\". The attribute that I want to resolve to H3 grids at resolution 4 is called \"dummy_emissions\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b925b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from h3_indexer.utils.config import read_yaml_config, read_json_config\n",
    "import json\n",
    "\n",
    "job_config_json = \"\"\"{\n",
    "  \"name\": \"test\",\n",
    "  \"version\": \"1.0.0\",\n",
    "  \"h3_resolution\": 4,\n",
    "  \"output_s3_path\": \"wws-air-quality\",\n",
    "  \"inputs\": {\n",
    "    \"routes\": {\n",
    "      \"type\": \"vector\",\n",
    "      \"s3_path\": \"wws-air-quality/testing/routes_03012025_tx/\",\n",
    "      \"unique_id\": \"route_id\",\n",
    "      \"geometry_type\": \"LINE\",\n",
    "      \"geometry_column_name\": \"geom_geojson\",\n",
    "      \"method\": \"PCT_LENGTH\",\n",
    "      \"input_columns\": [\n",
    "        \"dummy_emissions\"\n",
    "      ]\n",
    "    }\n",
    "  }\n",
    "}\"\"\"\n",
    "\n",
    "job_config = read_json_config(json.loads(job_config_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b3dd123",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/local/home/madiejf/h3-indexer-env/aws-glue-libs/jarsv1/slf4j-reload4j-1.7.36.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/local/home/madiejf/h3-indexer-env/spark-3.3.0-amzn-1-bin-3.3.3-amzn-0/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/local/home/madiejf/h3-indexer-env/spark-3.3.0-amzn-1-bin-3.3.3-amzn-0/spark/jars/slf4j-reload4j-1.7.36.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.slf4j.impl.Reload4jLoggerFactory]\n",
      "https://artifacts.unidata.ucar.edu/repository/unidata-all added as a remote repository with the name: repo-1\n",
      "Ivy Default Cache set to: /home/madiejf/.ivy2/cache\n",
      "The jars for the packages stored in: /home/madiejf/.ivy2/jars\n",
      "org.apache.sedona#sedona-spark-shaded-3.3_2.12 added as a dependency\n",
      "org.datasyslab#geotools-wrapper added as a dependency\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-ed229a92-025b-42db-8832-f59b90816d14;1.0\n",
      "\tconfs: [default]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/local/home/madiejf/h3-indexer-env/aws-glue-libs/jarsv1/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound org.apache.sedona#sedona-spark-shaded-3.3_2.12;1.7.1 in central\n",
      "\tfound org.datasyslab#geotools-wrapper;1.7.1-28.5 in central\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.4.1 in central\n",
      "\tfound software.amazon.awssdk#bundle;2.24.6 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.1.3.Final in central\n",
      ":: resolution report :: resolve 229ms :: artifacts dl 7ms\n",
      "\t:: modules in use:\n",
      "\torg.apache.hadoop#hadoop-aws;3.4.1 from central in [default]\n",
      "\torg.apache.sedona#sedona-spark-shaded-3.3_2.12;1.7.1 from central in [default]\n",
      "\torg.datasyslab#geotools-wrapper;1.7.1-28.5 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.1.3.Final from central in [default]\n",
      "\tsoftware.amazon.awssdk#bundle;2.24.6 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   5   |   0   |   0   |   0   ||   5   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-ed229a92-025b-42db-8832-f59b90816d14\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 5 already retrieved (0kB/7ms)\n",
      "log4j:WARN No appenders could be found for logger (org.apache.spark.util.ShutdownHookManager).\n",
      "log4j:WARN Please initialize the log4j system properly.\n",
      "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.\n",
      "                                                                                me version 4.7.2ANTLR Runtime version 4.8 used for parser compilation does not match the current runtime version 4.7.2ANTLR Tool version 4.8 used for code generation does not match the current runtime version 4.7.2ANTLR Runtime version 4.8 used for parser compilation does not match the current runtime version 4.7.2\r"
     ]
    }
   ],
   "source": [
    "from h3_indexer.spark.spark import get_spark_session\n",
    "spark, _ = get_spark_session(job_config.h3_resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e83ee7",
   "metadata": {},
   "source": [
    "### Preview the Routes data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d5f4401",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema:\n",
      "root\n",
      " |-- route_id: string (nullable = true)\n",
      " |-- geom: string (nullable = true)\n",
      " |-- dummy_emissions: double (nullable = true)\n",
      " |-- geom_geojson: string (nullable = true)\n",
      "\n",
      "\n",
      "Sample data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|            route_id|                geom|     dummy_emissions|        geom_geojson|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|01936312-1499-410...|01020000001a00000...|0.002798218687786...|{\"type\":\"LineStri...|\n",
      "|08039121-822d-489...|01020000002400000...|  5.3253454404509E-4|{\"type\":\"LineStri...|\n",
      "|0b7d13a5-a77e-46e...|01020000001000000...|2.571212936000028E-4|{\"type\":\"LineStri...|\n",
      "|        14619541-111|01020000003400000...|0.002819897809944...|{\"type\":\"LineStri...|\n",
      "|         14619696-70|01020000005c00000...|0.003055982783492923|{\"type\":\"LineStri...|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Total routes: 1000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s3_path = \"s3a://wws-air-quality/testing/routes_03012025_tx/\"\n",
    "\n",
    "# Load the parquet file into a PySpark DataFrame\n",
    "routes_df = spark.read.parquet(s3_path)\n",
    "\n",
    "# Show schema and sample data\n",
    "print(\"Schema:\")\n",
    "routes_df.printSchema()\n",
    "print(\"\\nSample data:\")\n",
    "routes_df.show(5)\n",
    "print(f\"\\nTotal routes: {routes_df.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a286637d",
   "metadata": {},
   "source": [
    "### Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36b89c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:All specified input columns are numeric.\n",
      "INFO:root:Total rows in input routes: 1000\n",
      "INFO:root:Valid geometries in input routes: 1000\n",
      "INFO:root:Removed invalid geometries in input routes: 0\n"
     ]
    }
   ],
   "source": [
    "from h3_indexer.validator import validate_config\n",
    "\n",
    "job = validate_config(job_config, spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cab658f",
   "metadata": {},
   "source": [
    "### Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cb2b90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Exporting to S3: s3://wws-air-quality/test/indexer/routes             \n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from main import index_job\n",
    "\n",
    "index_job(job, spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ced738a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+---------------+------------------+-----------+-------------------+------------------+\n",
      "|       h3_index|h3_resolution|   h3_r3_parent|       h3_area_km2|   route_id|              ratio|   total_length_km|\n",
      "+---------------+-------------+---------------+------------------+-----------+-------------------+------------------+\n",
      "|84444d9ffffffff|            4|83444dfffffffff|1940.1190723384705| 14619111-9|0.06684305377665199|192.26525333611414|\n",
      "|84444dbffffffff|            4|83444dfffffffff|1940.1063931159267|14621075-51|0.21388388573060046| 81.90121737051786|\n",
      "|84444d9ffffffff|            4|83444dfffffffff|1940.1190723384705| 14619111-8|0.04990429293934751| 181.6751815613184|\n",
      "|84444dbffffffff|            4|83444dfffffffff|1940.1063931159267|14620524-62|0.23078896914958355| 84.27524627831124|\n",
      "|8426d0bffffffff|            4|8326d0fffffffff|1987.1533604416047|14620546-40|  0.457986480328869| 72.30157040041772|\n",
      "+---------------+-------------+---------------+------------------+-----------+-------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "job.inputs['routes'].h3_indexed_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96458ef3",
   "metadata": {},
   "source": [
    "### Resolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48b46917",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Exporting to S3: s3://wws-air-quality/test/resolver                   \n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from main import resolve_job\n",
    "\n",
    "resolve_job(job, spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e435338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+---------------+------------------+--------------------+\n",
      "|       h3_index|h3_resolution|   h3_r3_parent|       h3_area_km2| sum_dummy_emissions|\n",
      "+---------------+-------------+---------------+------------------+--------------------+\n",
      "|8426c89ffffffff|            4|8326c8fffffffff|1956.4490093197985|0.009890607188183052|\n",
      "|84446c9ffffffff|            4|83446cfffffffff|1985.9623553970523|0.014567905321624462|\n",
      "|8426c8bffffffff|            4|8326c8fffffffff| 1957.471829299016|0.004658291294159675|\n",
      "|84489c9ffffffff|            4|83489cfffffffff| 2044.078627833024|0.007991191580432464|\n",
      "|8448923ffffffff|            4|834892fffffffff|1992.9078314864244|0.001300773557359...|\n",
      "+---------------+-------------+---------------+------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "job.h3_resolved_df.show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "h5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
